import streamlit as st
import pandas as pd
import plotly.express as px
import numpy as np
import os
import yaml # For authenticator config
from yaml.loader import SafeLoader # For authenticator config
import streamlit_authenticator as stauth # For authentication
import geopandas as gpd # For shapefile handling
import zipfile # For unzipping shapefiles
import io # For handling file streams
import plotly.graph_objects as go # For maps
import folium
from streamlit_folium import st_folium

# --- Configuration ---
st.set_page_config(layout="wide", page_title="Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ Ø­Ø³Ø§Ø¨Ø¯Ø§Ø±ÛŒ Ø¢Ø¨")

# --- File Paths ---
# Define base paths
try:
    BASE_DIR = os.path.dirname(os.path.abspath(__file__))
except NameError:
    BASE_DIR = os.getcwd() # Fallback

DAM_DATA_PATH = os.path.join(BASE_DIR, 'data/Dam_6Apr25.txt')
GW_DATA_PATH = os.path.join(BASE_DIR, 'data/GW_6Apr25.txt')
TRANSFER_DATA_PATH = os.path.join(BASE_DIR, 'Transfer_Data.txt')
WASTEWATER_DATA_PATH = os.path.join(BASE_DIR, 'Wastewater_Data.txt')

names = ['John Smith', 'Rebecca Briggs']
usernames = ['jsmith', 'rbriggs']
passwords = ['123', '456']

hashed_passwords = stauth.Hasher(passwords).generate()

authenticator = stauth.Authenticate(names, usernames, hashed_passwords,
    'some_cookie_name', 'some_signature_key', cookie_expiry_days=30)

# name, authentication_status, username = authenticator.login('Login', 'main')


# --- Login Form ---
# name, authentication_status, username = authenticator.login('main') # Original call

# FIX: Modified call with check for None return value
login_result = authenticator.login('main')
if login_result:
    name, authentication_status, username = login_result
else:
    # If login returns None, something is wrong, likely config.
    # Set defaults to avoid further errors and show a message.
    name, authentication_status, username = (None, None, None)
    st.error("Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙˆØ±ÙˆØ¯. Ù„Ø·ÙØ§Ù‹ ÙØ§ÛŒÙ„ `config.yaml` Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯ Ùˆ Ø§Ø² ØµØ­Øª Ø¢Ù† Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø­Ø§ØµÙ„ Ù†Ù…Ø§ÛŒÛŒØ¯. Ø³Ù¾Ø³ Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø±Ø§ Ù…Ø¬Ø¯Ø¯Ø§Ù‹ Ø§Ø¬Ø±Ø§ Ú©Ù†ÛŒØ¯.")
    st.stop() # Stop execution if login failed fundamentally

# --- Main App Logic (Gated by Authentication) ---
if authentication_status:
    # --- Logout Button in Sidebar ---
    st.sidebar.write(f'Ø®ÙˆØ´ Ø¢Ù…Ø¯ÛŒØ¯ *{st.session_state["name"]}*')
    authenticator.logout('Ø®Ø±ÙˆØ¬', 'sidebar')
    # --- Helper Functions ---
    @st.cache_data
    def load_and_preprocess_data(file_path, expected_cols, rename_map, source_type, extraction_source_col=None, usage_col='Usage_Type', county_col='County', year_col='Water_Year_Str', id_col_standard='ID', renewable_col='Renewable_Status'):
        """Loads and preprocesses data, handling missing files, units, and adding necessary columns."""
        if not os.path.exists(file_path):
            essential_cols = [usage_col, county_col, 'Extraction_MCM', id_col_standard, 'Source_Type', 'Source_Name', year_col, renewable_col]
            return pd.DataFrame(columns=essential_cols)

        try:
            try:
                df = pd.read_csv(file_path, encoding='utf-8', low_memory=False)
            except UnicodeDecodeError:
                df = pd.read_csv(file_path, encoding='cp1256', low_memory=False)

            missing_cols = [col for col in expected_cols if col not in df.columns]
            if missing_cols:
                st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙØ§ÛŒÙ„ {os.path.basename(file_path)}. Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ø§Ù†ØªØ¸Ø§Ø± ÛŒØ§ÙØª Ù†Ø´Ø¯Ù†Ø¯: {missing_cols}.")
                essential_cols = [usage_col, county_col, 'Extraction_MCM', id_col_standard, 'Source_Type', 'Source_Name', year_col, renewable_col]
                return pd.DataFrame(columns=essential_cols)

            df = df.rename(columns=rename_map)

            # --- Standardize Essential Columns ---
            # ID Column
            if id_col_standard not in df.columns:
                st.error(f"Ø³ØªÙˆÙ† ID Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯ ('{id_col_standard}') Ù¾Ø³ Ø§Ø² ØªØºÛŒÛŒØ± Ù†Ø§Ù… Ø¯Ø± ÙØ§ÛŒÙ„ {os.path.basename(file_path)} ÛŒØ§ÙØª Ù†Ø´Ø¯.")
                if 'ID' in df.columns: df[id_col_standard] = df['ID'].astype(str); st.warning("Ø§Ø² Ø³ØªÙˆÙ† 'ID' Ù…ÙˆØ¬ÙˆØ¯ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø´Ø¯.")
                else: df[id_col_standard] = 'Ù†Ø§Ù…Ø´Ø®Øµ'
            else: df[id_col_standard] = df[id_col_standard].astype(str)

            # Extraction Column & Unit Conversion
            extraction_col_found = False
            if extraction_source_col and extraction_source_col in df.columns:
                df['Extraction_MCM'] = safe_to_numeric(df[extraction_source_col]).fillna(0)
                extraction_col_found = True
                if source_type == 'Groundwater':
                    df['Extraction_MCM'] = df['Extraction_MCM'] / 1_000_000
            elif 'Extraction_MCM' in df.columns:
                df['Extraction_MCM'] = safe_to_numeric(df['Extraction_MCM']).fillna(0)
                extraction_col_found = True
                if source_type == 'Groundwater':
                    if not df['Extraction_MCM'].empty and df['Extraction_MCM'].max() > 10000:
                        df['Extraction_MCM'] = df['Extraction_MCM'] / 1_000_000
            elif not df.empty and 'Extraction_MCM' in df.columns and not df['Extraction_MCM'].empty and df['Extraction_MCM'].max() > 10000 and source_type == 'Groundwater':
                df['Extraction_MCM'] = df['Extraction_MCM'] / 1_000_000

            if not extraction_col_found:
                df['Extraction_MCM'] = 0
                if not (source_type == 'Surface' and extraction_source_col == 'Dam_Extraction_Value'):
                    st.warning(f"Ø³ØªÙˆÙ† Ø¨Ø±Ø¯Ø§Ø´Øª ('{extraction_source_col}' ÛŒØ§ 'Extraction_MCM') Ø¨Ø±Ø§ÛŒ ÙØ§ÛŒÙ„ {os.path.basename(file_path)} ÛŒØ§ÙØª Ù†Ø´Ø¯. Ù…Ù‚Ø¯Ø§Ø± ØµÙØ± Ø¯Ø± Ù†Ø¸Ø± Ú¯Ø±ÙØªÙ‡ Ø´Ø¯.")

            # Source Type
            df['Source_Type'] = source_type

            # Source Name
            if 'Dam_Name' in df.columns: df['Source_Name'] = df['Dam_Name']
            elif source_type == 'Groundwater': df['Source_Name'] = 'Ù…Ù†Ø¨Ø¹ Ø²ÛŒØ±Ø²Ù…ÛŒÙ†ÛŒ ' + df[id_col_standard]
            elif source_type == 'Transfer' and 'Transfer_Source_Name' in df.columns: df['Source_Name'] = df['Transfer_Source_Name']
            elif source_type == 'Wastewater' and 'WW_Plant_Name' in df.columns: df['Source_Name'] = df['WW_Plant_Name']
            else: df['Source_Name'] = source_type + ' ' + df[id_col_standard]

            # Usage Type, County, Year, Renewable Status
            if usage_col not in df.columns: df[usage_col] = 'Ù†Ø§Ù…Ø´Ø®Øµ'
            df[usage_col] = df[usage_col].fillna('Ù†Ø§Ù…Ø´Ø®Øµ')
            if county_col not in df.columns: df[county_col] = 'Ù†Ø§Ù…Ø´Ø®Øµ'
            df[county_col] = df[county_col].fillna('Ù†Ø§Ù…Ø´Ø®Øµ')
            if year_col not in df.columns: df[year_col] = 'Ù†Ø§Ù…Ø´Ø®Øµ'
            df[year_col] = df[year_col].astype(str).fillna('Ù†Ø§Ù…Ø´Ø®Øµ')
            if renewable_col not in df.columns: df[renewable_col] = 'Ù†Ø§Ù…Ø´Ø®Øµ'
            df[renewable_col] = df[renewable_col].fillna('Ù†Ø§Ù…Ø´Ø®Øµ')

            # --- Specific Preprocessing ---
            if source_type == 'Surface' or source_type == 'Transfer':
                if 'Dam_Name' in df.columns:
                    df['Source_Type'] = np.where(df['Dam_Name'].isin(TRANSFER_DAM_NAMES), 'Transfer', 'Surface')
                    df.loc[df['Source_Type'] == 'Transfer', 'Source_Name'] = df['Dam_Name']
                    df.loc[df['Source_Type'] == 'Surface', 'Source_Name'] = df['Dam_Name']
            elif source_type == 'Groundwater':
                if 'Smart_Meter' in df.columns: df['Smart_Meter'] = df['Smart_Meter'].replace({'Ø¯Ø§Ø±Ø¯': 'Yes', 'Ù†Ø¯Ø§Ø±Ø¯': 'No', 0: 'No', 1: 'Yes'}).fillna('Ù†Ø§Ù…Ø´Ø®Øµ')
                if 'Study_Area' not in df.columns: df['Study_Area'] = 'Ù†Ø§Ù…Ø´Ø®Øµ'
                df['Study_Area'] = df['Study_Area'].fillna('Ù†Ø§Ù…Ø´Ø®Øµ')
                if 'Well_ID_Orig' in df.columns: df['Well_ID_Orig'] = df['Well_ID_Orig'].astype(str)

            # Select standardized essential columns plus extras
            essential_cols = ['Extraction_MCM', id_col_standard, 'Source_Type', 'Source_Name', usage_col, county_col, year_col, renewable_col]
            if source_type == 'Groundwater': essential_cols.extend(['Study_Area', 'Well_Type', 'Well_Status', 'Well_Depth_m', 'Operating_Hours', 'Flow_Rate_ls', 'Well_ID_Orig'])
            if source_type == 'Surface' or source_type == 'Transfer': essential_cols.extend(['Volume_Start_Year', 'Volume_End_Year', 'Level_Start_Year', 'Level_End_Year', 'Inflow', 'Leakage', 'Pumping_Out', 'Drainage', 'Evaporation', 'Sediment_Discharge', 'Intake_Discharge', 'Spillway_Discharge'])

            final_cols = [col for col in essential_cols if col in df.columns]
            df_final = df[final_cols].copy()
            df_final = df_final.rename(columns={id_col_standard: 'ID'})

            return df_final

        except FileNotFoundError:
            # st.error(f"Ø®Ø·Ø§: ÙØ§ÛŒÙ„ Ø¯Ø± Ù…Ø³ÛŒØ± {file_path} ÛŒØ§ÙØª Ù†Ø´Ø¯.") # Already handled by os.path.exists
            essential_cols = [usage_col, county_col, 'Extraction_MCM', 'ID', 'Source_Type', 'Source_Name', year_col, renewable_col]
            return pd.DataFrame(columns=essential_cols)
        except Exception as e:
            st.error(f"Ø®Ø·Ø§ÛŒÛŒ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ {os.path.basename(file_path)} Ø±Ø® Ø¯Ø§Ø¯: {e}")
            essential_cols = [usage_col, county_col, 'Extraction_MCM', 'ID', 'Source_Type', 'Source_Name', year_col, renewable_col]
            return pd.DataFrame(columns=essential_cols)


    def safe_to_numeric(series):
        """Converts a pandas Series to numeric, coercing errors to NaN."""
        return pd.to_numeric(series, errors='coerce')

    # --- Define Mappings and Constants ---
    TRANSFER_DAM_NAMES = ['Ø³Ø¯ Ø¯ÙˆØ³ØªÛŒ']

    dam_expected_cols = ['Year', 'Name of Dam', 'ØªØ±Ø§Ø² Ø§Ù†ØªÙ‡Ø§ÛŒ Ø³Ø§Ù„ Ø¢Ø¨ÛŒ', 'ØªØ±Ø§Ø² Ø§Ø¨ØªØ¯Ø§ÛŒ Ø³Ø§Ù„ Ø¢Ø¨ÛŒ', 'Ø­Ø¬Ù… Ø§Ù†ØªÙ‡Ø§ÛŒ Ø³Ø§Ù„ Ø¢Ø¨ÛŒ', 'Ø­Ø¬Ù… Ø§Ø¨ØªØ¯Ø§ÛŒ Ø³Ø§Ù„ Ø¢Ø¨ÛŒ', 'ÙˆØ±ÙˆØ¯ÛŒ', 'Ø³Ø§ÛŒØ±', 'ÙƒÙ„', 'Ù†Ø´ØªÙŠ', 'Ù¾Ù…Ù¾Ø§Ú˜', 'Ø²Ù‡ÙƒØ´', 'ØªØ¨Ø®ÙŠØ±', 'ØªØ®Ù„ÛŒÙ‡ Ø±Ø³ÙˆØ¨', 'Ø¯Ø±ÙŠÚ†Ù‡ Ø¢Ø¨Ú¯ÙŠØ±ÙŠ', 'Ø³Ø±Ø±ÙŠØ²', 'Ú©Ù„', 'Type of Use', 'ID', 'Value', 'sharestan']
    dam_rename_map = {'Year': 'Water_Year_Str', 'Name of Dam': 'Dam_Name', 'ØªØ±Ø§Ø² Ø§Ù†ØªÙ‡Ø§ÛŒ Ø³Ø§Ù„ Ø¢Ø¨ÛŒ': 'Level_End_Year', 'ØªØ±Ø§Ø² Ø§Ø¨ØªØ¯Ø§ÛŒ Ø³Ø§Ù„ Ø¢Ø¨ÛŒ': 'Level_Start_Year', 'Ø­Ø¬Ù… Ø§Ù†ØªÙ‡Ø§ÛŒ Ø³Ø§Ù„ Ø¢Ø¨ÛŒ': 'Volume_End_Year', 'Ø­Ø¬Ù… Ø§Ø¨ØªØ¯Ø§ÛŒ Ø³Ø§Ù„ Ø¢Ø¨ÛŒ': 'Volume_Start_Year', 'ÙˆØ±ÙˆØ¯ÛŒ': 'Inflow', 'Ø³Ø§ÛŒØ±': 'Other_Input', 'ÙƒÙ„': 'Total_Input', 'Ù†Ø´ØªÙŠ': 'Leakage', 'Ù¾Ù…Ù¾Ø§Ú˜': 'Pumping_Out', 'Ø²Ù‡ÙƒØ´': 'Drainage', 'ØªØ¨Ø®ÙŠØ±': 'Evaporation', 'ØªØ®Ù„ÛŒÙ‡ Ø±Ø³ÙˆØ¨': 'Sediment_Discharge', 'Ø¯Ø±ÙŠÚ†Ù‡ Ø¢Ø¨Ú¯ÙŠØ±ÙŠ': 'Intake_Discharge', 'Ø³Ø±Ø±ÙŠØ²': 'Spillway_Discharge', 'Ú©Ù„': 'Total_Outflow', 'Type of Use': 'Usage_Type', 'ID': 'SubBasin_ID', 'Value': 'Dam_Extraction_Value', 'sharestan': 'County'}

    gw_expected_cols = ['Ø³Ø§Ù„ Ø¢Ø¨ÙŠ', 'Ø§Ø´ØªØ±Ø§Ú©', 'Ø§Ù…ÙˆØ±', 'Ø§Ø´ØªØ±Ø§Ú© Ø¨Ø±Ù‚', 'Ù…Ø­Ø¯ÙˆØ¯Ù‡ Ù…Ø·Ø§Ù„Ø¹Ø§ØªÙŠ', 'Ø´Ù‡Ø±Ø³ØªØ§Ù†', 'MA_XUTM', 'MA_YUTM', 'Ø¹Ù…Ù‚ Ú†Ø§Ù‡', 'Ø¯Ø¨ÙŠ', 'Ø³Ø§Ø¹Øª Ú©Ø§Ø±Ú©Ø±Ø¯', 'Ø§Ø¶Ø§ÙÙ‡ Ú©Ø³Ø±Ø¨Ø±Ø¯Ø§Ø´Øª', 'ØªØ®Ù„ÙŠÙ‡ Ù…ØªØ±Ù…Ú©Ø¹Ø¨', 'Ù†ÙˆØ¹ Ú†Ø§Ù‡', 'Ù†ÙˆØ¹ Ù…ØµØ±Ù', 'Ù†ÙŠØ±Ùˆ Ù…Ø­Ø±Ú©Ù‡', 'ÙˆØ¶Ø¹ÙŠØª Ú†Ø§Ù‡', 'Ø¨Ø±Ø¯Ø§Ø´Øª ÙˆØ§Ù‚Ø¹ÙŠ', 'Ú©Ù†ØªÙˆØ± Ù‡ÙˆØ´Ù…Ù†Ø¯', 'conat', 'ID']
    gw_rename_map = {'Ø³Ø§Ù„ Ø¢Ø¨ÙŠ': 'Water_Year_Str', 'Ø§Ø´ØªØ±Ø§Ú©': 'Subscription_ID', 'Ø§Ù…ÙˆØ±': 'Department', 'Ø§Ø´ØªØ±Ø§Ú© Ø¨Ø±Ù‚': 'Electricity_Subscription', 'Ù…Ø­Ø¯ÙˆØ¯Ù‡ Ù…Ø·Ø§Ù„Ø¹Ø§ØªÙŠ': 'Study_Area', 'Ø´Ù‡Ø±Ø³ØªØ§Ù†': 'County', 'MA_XUTM': 'X_UTM', 'MA_YUTM': 'Y_UTM', 'Ø¹Ù…Ù‚ Ú†Ø§Ù‡': 'Well_Depth_m', 'Ø¯Ø¨ÙŠ': 'Flow_Rate_ls', 'Ø³Ø§Ø¹Øª Ú©Ø§Ø±Ú©Ø±Ø¯': 'Operating_Hours', 'Ø§Ø¶Ø§ÙÙ‡ Ú©Ø³Ø±Ø¨Ø±Ø¯Ø§Ø´Øª': 'Over_Under_Extraction_m3', 'ØªØ®Ù„ÙŠÙ‡ Ù…ØªØ±Ù…Ú©Ø¹Ø¨': 'Discharge_m3', 'Ù†ÙˆØ¹ Ú†Ø§Ù‡': 'Well_Type', 'Ù†ÙˆØ¹ Ù…ØµØ±Ù': 'Usage_Type', 'Ù†ÙŠØ±Ùˆ Ù…Ø­Ø±Ú©Ù‡': 'Power_Source', 'ÙˆØ¶Ø¹ÙŠØª Ú†Ø§Ù‡': 'Well_Status', 'Ø¨Ø±Ø¯Ø§Ø´Øª ÙˆØ§Ù‚Ø¹ÙŠ': 'Actual_Extraction_m3', 'Ú©Ù†ØªÙˆØ± Ù‡ÙˆØ´Ù…Ù†Ø¯': 'Smart_Meter', 'conat': 'Coordinates_Text', 'ID': 'SubBasin_ID'}

    transfer_expected_cols = ['Water_Year', 'Source_Name', 'Extraction_MCM', 'Usage_Type', 'County', 'ID', 'Renewable_Status']
    transfer_rename_map = {'Water_Year': 'Water_Year_Str', 'Source_Name': 'Transfer_Source_Name', 'Extraction_MCM': 'Extraction_MCM', 'Usage_Type': 'Usage_Type', 'County': 'County', 'ID': 'SubBasin_ID', 'Renewable_Status': 'Renewable_Status'}

    ww_expected_cols = ['Water_Year', 'Plant_Name', 'Treated_Volume_MCM', 'Usage_Type', 'County', 'ID', 'Renewable_Status']
    ww_rename_map = {'Water_Year': 'Water_Year_Str', 'Plant_Name': 'WW_Plant_Name', 'Treated_Volume_MCM': 'Extraction_MCM', 'Usage_Type': 'Usage_Type', 'County': 'County', 'ID': 'SubBasin_ID', 'Renewable_Status': 'Renewable_Status'}


    # --- Load All Data ---
    df_dam_raw = load_and_preprocess_data(DAM_DATA_PATH, dam_expected_cols, dam_rename_map, 'Surface', extraction_source_col='Dam_Extraction_Value', id_col_standard='SubBasin_ID', year_col='Water_Year_Str')
    df_gw_raw = load_and_preprocess_data(GW_DATA_PATH, gw_expected_cols, gw_rename_map, 'Groundwater', extraction_source_col='Actual_Extraction_m3', id_col_standard='SubBasin_ID', year_col='Water_Year_Str')
    df_transfer_raw = load_and_preprocess_data(TRANSFER_DATA_PATH, transfer_expected_cols, transfer_rename_map, 'Transfer', extraction_source_col='Extraction_MCM', id_col_standard='SubBasin_ID', year_col='Water_Year_Str')
    df_wastewater_raw = load_and_preprocess_data(WASTEWATER_DATA_PATH, ww_expected_cols, ww_rename_map, 'Wastewater', extraction_source_col='Extraction_MCM', id_col_standard='SubBasin_ID', year_col='Water_Year_Str')

    df_all_data = pd.concat([df_dam_raw, df_gw_raw, df_transfer_raw, df_wastewater_raw], ignore_index=True)


    # --- Sidebar Navigation and Filters ---
    st.sidebar.title("Ø±Ø§Ù‡Ø¨Ø±ÛŒ")
    app_mode = st.sidebar.radio("Ø§Ù†ØªØ®Ø§Ø¨ ØµÙØ­Ù‡ Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯", ["ØªØ­Ù„ÛŒÙ„ Ø¬Ø²Ø¦ÛŒ", "Ø®Ù„Ø§ØµÙ‡ Ø¨ÛŒÙ„Ø§Ù† Ø¢Ø¨"])
    st.sidebar.divider()
    st.sidebar.header("ÙÛŒÙ„ØªØ±Ù‡Ø§ÛŒ Ø¹Ù…ÙˆÙ…ÛŒ")

    all_water_years_options = []
    latest_year = None
    if not df_all_data.empty and 'Water_Year_Str' in df_all_data.columns:
         valid_years_list = sorted(df_all_data['Water_Year_Str'].dropna().unique(), reverse=True)
         all_water_years_options = [yr for yr in valid_years_list if yr not in ['nan', 'Ù†Ø§Ù…Ø´Ø®Øµ', 'None']]
         if all_water_years_options: latest_year = all_water_years_options[0]
    selected_water_years = st.sidebar.multiselect("Ø§Ù†ØªØ®Ø§Ø¨ Ø³Ø§Ù„(Ù‡Ø§ÛŒ) Ø¢Ø¨ÛŒ", options=all_water_years_options, default=[latest_year] if latest_year else [])

    all_counties = ['Ù‡Ù…Ù‡']
    if not df_all_data.empty and 'County' in df_all_data.columns:
        all_counties.extend(sorted(list(set(c for c in df_all_data['County'].dropna().unique() if c != 'Ù†Ø§Ù…Ø´Ø®Øµ'))))
    selected_county_sidebar = st.sidebar.selectbox("Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ù‡Ø±Ø³ØªØ§Ù†", options=all_counties, key="county_sidebar_filter")


    # --- Filter DataFrames Globally ---
    df_filtered = df_all_data.copy()
    if selected_water_years: df_filtered = df_filtered[df_filtered['Water_Year_Str'].isin(selected_water_years)]
    if selected_county_sidebar != "Ù‡Ù…Ù‡": df_filtered = df_filtered[df_filtered['County'] == selected_county_sidebar]

    df_dam_detailed = df_filtered[df_filtered['Source_Type'].isin(['Surface', 'Transfer'])].copy()
    df_gw_detailed = df_filtered[df_filtered['Source_Type'] == 'Groundwater'].copy()


    # --- Page Display Functions ---

    def display_detailed_analysis(df_dam_viz, df_gw_viz):
        """Displays the detailed charts and tables."""
        st.title("ğŸ’§ Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ Ø­Ø³Ø§Ø¨Ø¯Ø§Ø±ÛŒ Ø¢Ø¨ - ØªØ­Ù„ÛŒÙ„ Ø¬Ø²Ø¦ÛŒ")

        st.header("ğŸŒŠ ØªØ­Ù„ÛŒÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø³Ø¯ Ùˆ Ø¢Ø¨ Ø§Ù†ØªÙ‚Ø§Ù„ÛŒ")

        if df_dam_viz is None or df_dam_viz.empty:
            st.warning(f"Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø³Ø¯/Ø§Ù†ØªÙ‚Ø§Ù„ÛŒ Ø¨Ø§ ÙÛŒÙ„ØªØ±Ù‡Ø§ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯Ù‡ ÛŒØ§ÙØª Ù†Ø´Ø¯ (Ø³Ø§Ù„ Ø¢Ø¨ÛŒ: {selected_water_years}, Ø´Ù‡Ø±Ø³ØªØ§Ù†: {selected_county_sidebar}).")
        else:
            dam_names = ['Ù‡Ù…Ù‡'] + sorted(df_dam_viz['Source_Name'].dropna().unique())
            selected_dam = st.selectbox("Ø§Ù†ØªØ®Ø§Ø¨ Ø³Ø¯ / Ù…Ù†Ø¨Ø¹ Ø§Ù†ØªÙ‚Ø§Ù„ÛŒ", dam_names, key="dam_select_detail")
            df_dam_viz_filtered = df_dam_viz if selected_dam == "Ù‡Ù…Ù‡" else df_dam_viz[df_dam_viz['Source_Name'] == selected_dam]

            if not df_dam_viz_filtered.empty:
                plot_numeric_cols = ['Volume_Start_Year', 'Volume_End_Year', 'Level_Start_Year', 'Level_End_Year', 'Inflow', 'Leakage', 'Pumping_Out', 'Drainage', 'Evaporation', 'Sediment_Discharge', 'Intake_Discharge', 'Spillway_Discharge', 'Extraction_MCM']
                for col in plot_numeric_cols:
                    if col not in df_dam_viz_filtered.columns: df_dam_viz_filtered[col] = 0
                    else: df_dam_viz_filtered[col] = safe_to_numeric(df_dam_viz_filtered[col]).fillna(0)

                col1, col2 = st.columns(2)
                if 'Volume_Start_Year' in df_dam_viz_filtered.columns and 'Volume_End_Year' in df_dam_viz_filtered.columns:
                    with col1:
                        st.subheader("Ø­Ø¬Ù… Ø¢Ø¨ Ø³Ø¯ (MCM)")
                        fig_dam_vol = px.line(df_dam_viz_filtered, x='Water_Year_Str', y=['Volume_Start_Year', 'Volume_End_Year'], title=f"Ø­Ø¬Ù… Ø¢Ø¨ Ø¨Ø±Ø§ÛŒ {selected_dam}", labels={'Water_Year_Str': 'Ø³Ø§Ù„ Ø¢Ø¨ÛŒ', 'value': 'Ø­Ø¬Ù… (Ù…ÛŒÙ„ÛŒÙˆÙ† Ù…ØªØ± Ù…Ú©Ø¹Ø¨)', 'variable': 'Ø§Ù†Ø¯Ø§Ø²Ù‡â€ŒÚ¯ÛŒØ±ÛŒ'}, markers=True)
                        st.plotly_chart(fig_dam_vol, use_container_width=True)
                else: # Indentation fixed
                    with col1:
                        st.info("Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø­Ø¬Ù… Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª.")
                if 'Level_Start_Year' in df_dam_viz_filtered.columns and 'Level_End_Year' in df_dam_viz_filtered.columns:
                    with col2:
                        st.subheader("ØªØ±Ø§Ø² Ø¢Ø¨ Ø³Ø¯ (m)")
                        fig_dam_level = px.line(df_dam_viz_filtered, x='Water_Year_Str', y=['Level_Start_Year', 'Level_End_Year'], title=f"ØªØ±Ø§Ø² Ø¢Ø¨ Ø¨Ø±Ø§ÛŒ {selected_dam}", labels={'Water_Year_Str': 'Ø³Ø§Ù„ Ø¢Ø¨ÛŒ', 'value': 'ØªØ±Ø§Ø² (Ù…ØªØ±)', 'variable': 'Ø§Ù†Ø¯Ø§Ø²Ù‡â€ŒÚ¯ÛŒØ±ÛŒ'}, markers=True)
                        st.plotly_chart(fig_dam_level, use_container_width=True)
                else: # Indentation fixed
                    with col2:
                        st.info("Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ±Ø§Ø² Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª.")

                st.subheader(f"Ù…ÙˆÙ„ÙÙ‡â€ŒÙ‡Ø§ÛŒ Ø¨ÛŒÙ„Ø§Ù† Ø¢Ø¨ Ø¨Ø±Ø§ÛŒ {selected_dam} (MCM)")
                balance_cols = ['Inflow', 'Leakage', 'Pumping_Out', 'Drainage', 'Evaporation', 'Sediment_Discharge', 'Intake_Discharge', 'Spillway_Discharge', 'Extraction_MCM']
                balance_cols_present = [col for col in balance_cols if col in df_dam_viz_filtered.columns]
                if balance_cols_present:
                    df_balance = df_dam_viz_filtered.groupby('Water_Year_Str')[balance_cols_present].sum().reset_index() if selected_dam == "Ù‡Ù…Ù‡" else df_dam_viz_filtered[['Water_Year_Str'] + balance_cols_present].copy()
                    title_suffix = "(ØªØ¬Ù…ÛŒØ¹ÛŒ)" if selected_dam == "Ù‡Ù…Ù‡" else f"Ø¨Ø±Ø§ÛŒ {selected_dam}"
                    df_balance_melt = df_balance.melt(id_vars='Water_Year_Str', value_vars=balance_cols_present, var_name='Ù…ÙˆÙ„ÙÙ‡', value_name='Ø­Ø¬Ù… (MCM)')
                    fig_balance = px.bar(df_balance_melt, x='Water_Year_Str', y='Ø­Ø¬Ù… (MCM)', color='Ù…ÙˆÙ„ÙÙ‡', title=f"Ù…ÙˆÙ„ÙÙ‡â€ŒÙ‡Ø§ÛŒ Ø¨ÛŒÙ„Ø§Ù† Ø¢Ø¨ {title_suffix} ({', '.join(selected_water_years)})", labels={'Water_Year_Str': 'Ø³Ø§Ù„ Ø¢Ø¨ÛŒ'}, barmode='group').update_xaxes(categoryorder='array', categoryarray=sorted(df_balance_melt['Water_Year_Str'].unique())) # Sort x-axis
                    st.plotly_chart(fig_balance, use_container_width=True)
                else: st.info("Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…ÙˆÙ„ÙÙ‡â€ŒÙ‡Ø§ÛŒ Ø¨ÛŒÙ„Ø§Ù† Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª.")

                st.subheader(f"Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙÛŒÙ„ØªØ± Ø´Ø¯Ù‡ Ø³Ø¯/Ø§Ù†ØªÙ‚Ø§Ù„ÛŒ ({selected_dam})")
                st.dataframe(df_dam_viz_filtered)
            else: st.warning(f"Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø³Ø¯/Ø§Ù†ØªÙ‚Ø§Ù„ÛŒ Ø¨Ø§ ÙÛŒÙ„ØªØ±Ù‡Ø§ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯Ù‡ ÛŒØ§ÙØª Ù†Ø´Ø¯ (Ø³Ø§Ù„ Ø¢Ø¨ÛŒ: {selected_water_years}, Ø´Ù‡Ø±Ø³ØªØ§Ù†: {selected_county_sidebar}, Ù…Ù†Ø¨Ø¹: {selected_dam}).")

        st.divider()
        st.header("ğŸŒ ØªØ­Ù„ÛŒÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¢Ø¨ Ø²ÛŒØ±Ø²Ù…ÛŒÙ†ÛŒ")
        if df_gw_viz is None or df_gw_viz.empty:
            st.warning(f"Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø¢Ø¨ Ø²ÛŒØ±Ø²Ù…ÛŒÙ†ÛŒ Ø¨Ø§ ÙÛŒÙ„ØªØ±Ù‡Ø§ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯Ù‡ ÛŒØ§ÙØª Ù†Ø´Ø¯ (Ø³Ø§Ù„ Ø¢Ø¨ÛŒ: {selected_water_years}, Ø´Ù‡Ø±Ø³ØªØ§Ù†: {selected_county_sidebar}).")
        else:
            gw_usage_types = ['Ù‡Ù…Ù‡'] + sorted(df_gw_viz['Usage_Type'].dropna().unique())
            selected_gw_usage = st.selectbox("Ø§Ù†ØªØ®Ø§Ø¨ Ù†ÙˆØ¹ Ú©Ø§Ø±Ø¨Ø±ÛŒ Ø¢Ø¨ Ø²ÛŒØ±Ø²Ù…ÛŒÙ†ÛŒ", gw_usage_types, key="gw_usage_detail")
            selected_well_type = "Ù‡Ù…Ù‡"
            if 'Well_Type' in df_gw_viz.columns:
                gw_well_types = ['Ù‡Ù…Ù‡'] + sorted(df_gw_viz['Well_Type'].dropna().unique())
                selected_well_type = st.selectbox("Ø§Ù†ØªØ®Ø§Ø¨ Ù†ÙˆØ¹ Ú†Ø§Ù‡", gw_well_types, key="gw_well_type_detail")
            selected_well_status = "Ù‡Ù…Ù‡"
            if 'Well_Status' in df_gw_viz.columns:
                gw_well_status = ['Ù‡Ù…Ù‡'] + sorted(df_gw_viz['Well_Status'].dropna().unique())
                selected_well_status = st.selectbox("Ø§Ù†ØªØ®Ø§Ø¨ ÙˆØ¶Ø¹ÛŒØª Ú†Ø§Ù‡", gw_well_status, key="gw_status_detail")

            df_gw_viz_filtered = df_gw_viz
            if selected_gw_usage != "Ù‡Ù…Ù‡": df_gw_viz_filtered = df_gw_viz_filtered[df_gw_viz_filtered['Usage_Type'] == selected_gw_usage]
            if selected_well_type != "Ù‡Ù…Ù‡" and 'Well_Type' in df_gw_viz_filtered.columns: df_gw_viz_filtered = df_gw_viz_filtered[df_gw_viz_filtered['Well_Type'] == selected_well_type]
            if selected_well_status != "Ù‡Ù…Ù‡" and 'Well_Status' in df_gw_viz_filtered.columns: df_gw_viz_filtered = df_gw_viz_filtered[df_gw_viz_filtered['Well_Status'] == selected_well_status]

            if not df_gw_viz_filtered.empty:
                total_extraction_mcm = df_gw_viz_filtered['Extraction_MCM'].sum()
                avg_depth = df_gw_viz_filtered['Well_Depth_m'].mean() if 'Well_Depth_m' in df_gw_viz_filtered.columns else np.nan
                num_subbasins = df_gw_viz_filtered['ID'].nunique()

                st.subheader("Ù…Ù‚Ø§Ø¯ÛŒØ± Ø®Ù„Ø§ØµÙ‡ (ÙÛŒÙ„ØªØ± Ø´Ø¯Ù‡)")
                mcol1, mcol2, mcol3 = st.columns(3)
                mcol1.metric("Ù…Ø¬Ù…ÙˆØ¹ Ø¨Ø±Ø¯Ø§Ø´Øª (Ù…ÛŒÙ„ÛŒÙˆÙ† Ù…ØªØ± Ù…Ú©Ø¹Ø¨)", f"{total_extraction_mcm:,.2f}")
                mcol2.metric("Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø¹Ù…Ù‚ Ú†Ø§Ù‡ (Ù…ØªØ±)", f"{avg_depth:.1f}" if not pd.isna(avg_depth) else "N/A")
                mcol3.metric("ØªØ¹Ø¯Ø§Ø¯ Ø²ÛŒØ±Ø­ÙˆØ¶Ù‡â€ŒÙ‡Ø§ÛŒ ÙØ¹Ø§Ù„", f"{num_subbasins}")

                st.subheader("Ù…Ø¬Ù…ÙˆØ¹ Ø¨Ø±Ø¯Ø§Ø´Øª Ø¢Ø¨ Ø²ÛŒØ±Ø²Ù…ÛŒÙ†ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø³Ø§Ù„ Ø¢Ø¨ÛŒ Ùˆ Ù†ÙˆØ¹ Ú©Ø§Ø±Ø¨Ø±ÛŒ (MCM)")
                df_gw_agg_usage = df_gw_viz_filtered.groupby(['Water_Year_Str', 'Usage_Type'])['Extraction_MCM'].sum().reset_index()
                fig_gw_usage = px.bar(df_gw_agg_usage, x='Water_Year_Str', y='Extraction_MCM', color='Usage_Type', title=f"Ø¨Ø±Ø¯Ø§Ø´Øª Ø³Ø§Ù„Ø§Ù†Ù‡ Ø¢Ø¨ Ø²ÛŒØ±Ø²Ù…ÛŒÙ†ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†ÙˆØ¹ Ú©Ø§Ø±Ø¨Ø±ÛŒ ({', '.join(selected_water_years)})", labels={'Water_Year_Str': 'Ø³Ø§Ù„ Ø¢Ø¨ÛŒ', 'Extraction_MCM': 'Ù…Ø¬Ù…ÙˆØ¹ Ø¨Ø±Ø¯Ø§Ø´Øª (Ù…ÛŒÙ„ÛŒÙˆÙ† Ù…ØªØ± Ù…Ú©Ø¹Ø¨)'}).update_xaxes(categoryorder='array', categoryarray=sorted(df_gw_agg_usage['Water_Year_Str'].unique())) # Sort x-axis
                st.plotly_chart(fig_gw_usage, use_container_width=True)

                col3, col4 = st.columns(2)
                if 'Well_Type' in df_gw_viz_filtered.columns:
                    with col3:
                        st.subheader("ØªÙˆØ²ÛŒØ¹ Ù†ÙˆØ¹ Ú†Ø§Ù‡ (Ø¨Ø± Ø§Ø³Ø§Ø³ ØªØ¹Ø¯Ø§Ø¯)")
                        count_col = 'Well_ID_Orig' if 'Well_ID_Orig' in df_gw_viz_filtered.columns else 'ID'
                        df_gw_count_type = df_gw_viz_filtered.groupby('Well_Type')[count_col].nunique().reset_index().rename(columns={count_col: 'Count'})
                        fig_gw_type = px.pie(df_gw_count_type, names='Well_Type', values='Count', title="ØªÙˆØ²ÛŒØ¹ Ø§Ù†ÙˆØ§Ø¹ Ú†Ø§Ù‡", hole=0.3)
                        st.plotly_chart(fig_gw_type, use_container_width=True)
                # FIX: Correct indentation for else block (Line 297 original)
                else:
                    with col3:
                        st.info("Ø¯Ø§Ø¯Ù‡ Ù†ÙˆØ¹ Ú†Ø§Ù‡ Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª.")
                if 'Well_Status' in df_gw_viz_filtered.columns:
                    with col4:
                        st.subheader("ØªÙˆØ²ÛŒØ¹ ÙˆØ¶Ø¹ÛŒØª Ú†Ø§Ù‡ (Ø¨Ø± Ø§Ø³Ø§Ø³ ØªØ¹Ø¯Ø§Ø¯)")
                        count_col = 'Well_ID_Orig' if 'Well_ID_Orig' in df_gw_viz_filtered.columns else 'ID'
                        df_gw_count_status = df_gw_viz_filtered.groupby('Well_Status')[count_col].nunique().reset_index().rename(columns={count_col: 'Count'})
                        fig_gw_status = px.pie(df_gw_count_status, names='Well_Status', values='Count', title="ØªÙˆØ²ÛŒØ¹ ÙˆØ¶Ø¹ÛŒØª Ú†Ø§Ù‡â€ŒÙ‡Ø§", hole=0.3)
                        st.plotly_chart(fig_gw_status, use_container_width=True)
                # FIX: Correct indentation for else block (Line 305 original)
                else:
                    with col4:
                        st.info("Ø¯Ø§Ø¯Ù‡ ÙˆØ¶Ø¹ÛŒØª Ú†Ø§Ù‡ Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª.")

                scatter_cols_exist = all(c in df_gw_viz_filtered.columns for c in ['Extraction_MCM', 'Operating_Hours', 'Flow_Rate_ls'])
                if scatter_cols_exist:
                    df_scatter = df_gw_viz_filtered[(df_gw_viz_filtered['Extraction_MCM'] > 0) & (df_gw_viz_filtered['Operating_Hours'] > 0)]
                    if not df_scatter.empty:
                        st.subheader("Ø¨Ø±Ø¯Ø§Ø´Øª (MCM) Ø¯Ø± Ù…Ù‚Ø§Ø¨Ù„ Ø³Ø§Ø¹Ø§Øª Ú©Ø§Ø±Ú©Ø±Ø¯")
                        fig_scatter = px.scatter(df_scatter, x='Operating_Hours', y='Extraction_MCM', color='Usage_Type', size='Flow_Rate_ls', hover_name='ID', title="Ø¨Ø±Ø¯Ø§Ø´Øª Ø¯Ø± Ù…Ù‚Ø§Ø¨Ù„ Ø³Ø§Ø¹Ø§Øª Ú©Ø§Ø±Ú©Ø±Ø¯ (Ø§Ù†Ø¯Ø§Ø²Ù‡ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¯Ø¨ÛŒ)", labels={'Operating_Hours': 'Ø³Ø§Ø¹Ø§Øª Ú©Ø§Ø±Ú©Ø±Ø¯', 'Extraction_MCM': 'Ø¨Ø±Ø¯Ø§Ø´Øª (Ù…ÛŒÙ„ÛŒÙˆÙ† Ù…ØªØ± Ù…Ú©Ø¹Ø¨)'})
                        st.plotly_chart(fig_scatter, use_container_width=True)
                    else: st.info("Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø§ Ø¨Ø±Ø¯Ø§Ø´Øª Ùˆ Ø³Ø§Ø¹Ø§Øª Ú©Ø§Ø±Ú©Ø±Ø¯ Ù…Ø«Ø¨Øª Ø¨Ø±Ø§ÛŒ Ù†Ù…ÙˆØ¯Ø§Ø± Ù¾Ø±Ø§Ú©Ù†Ø¯Ú¯ÛŒ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯.")
                else: st.info("Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ù„Ø§Ø²Ù… Ø¨Ø±Ø§ÛŒ Ù†Ù…ÙˆØ¯Ø§Ø± Ù¾Ø±Ø§Ú©Ù†Ø¯Ú¯ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³ØªÙ†Ø¯.")

                st.subheader("Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙÛŒÙ„ØªØ± Ø´Ø¯Ù‡ Ø¢Ø¨ Ø²ÛŒØ±Ø²Ù…ÛŒÙ†ÛŒ")
                st.dataframe(df_gw_viz_filtered)
            else: st.warning(f"Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø¢Ø¨ Ø²ÛŒØ±Ø²Ù…ÛŒÙ†ÛŒ Ø¨Ø§ ÙÛŒÙ„ØªØ±Ù‡Ø§ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯Ù‡ ÛŒØ§ÙØª Ù†Ø´Ø¯.")

    @st.cache_data # Cache shapefile reading
    def load_shapefile(uploaded_file):
        """Loads a shapefile from an uploaded zip file."""
        try:
            zip_buffer = io.BytesIO(uploaded_file.getvalue())
            with zipfile.ZipFile(zip_buffer) as z:
                shp_file_path = None
                for filename in z.namelist():
                    if filename.lower().endswith(".shp"): shp_file_path = filename; break
                if shp_file_path is None: st.error("ÙØ§ÛŒÙ„ .shp Ø¯Ø± ÙØ§ÛŒÙ„ ÙØ´Ø±Ø¯Ù‡ ÛŒØ§ÙØª Ù†Ø´Ø¯."); return None
                import tempfile
                with tempfile.TemporaryDirectory() as tmpdir:
                    z.extractall(path=tmpdir)
                    shp_full_path = os.path.join(tmpdir, shp_file_path)
                    if os.path.exists(shp_full_path):
                        gdf = gpd.read_file(shp_full_path)
                        if gdf.crs is None: gdf.set_crs("EPSG:4326", inplace=True); st.warning("Ø³ÛŒØ³ØªÙ… Ù…Ø®ØªØµØ§Øª (CRS) Ø¨Ø±Ø§ÛŒ Ø´ÛŒÙ¾â€ŒÙØ§ÛŒÙ„ Ù…Ø´Ø®Øµ Ù†Ø´Ø¯Ù‡ Ø¨ÙˆØ¯. EPSG:4326 (WGS84) Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø¯Ø± Ù†Ø¸Ø± Ú¯Ø±ÙØªÙ‡ Ø´Ø¯.")
                        gdf = gdf.to_crs("EPSG:4326")
                        return gdf
                    else: st.error("Ø®Ø·Ø§ Ø¯Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÛŒØ§ ÛŒØ§ÙØªÙ† ÙØ§ÛŒÙ„ .shp Ø¯Ø± Ù…Ø³ÛŒØ± Ù…ÙˆÙ‚Øª."); return None
        except zipfile.BadZipFile: st.error("ÙØ§ÛŒÙ„ Ø¢Ù¾Ù„ÙˆØ¯ Ø´Ø¯Ù‡ ÛŒÚ© ÙØ§ÛŒÙ„ ÙØ´Ø±Ø¯Ù‡ (zip) Ù…Ø¹ØªØ¨Ø± Ù†ÛŒØ³Øª."); return None
        except ImportError: st.error("Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡ geopandas ÛŒØ§ÙØª Ù†Ø´Ø¯. Ù„Ø·ÙØ§Ù‹ Ø¢Ù† Ø±Ø§ Ù†ØµØ¨ Ú©Ù†ÛŒØ¯: pip install geopandas"); return None
        except Exception as e: st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø®ÙˆØ§Ù†Ø¯Ù† Ø´ÛŒÙ¾â€ŒÙØ§ÛŒÙ„: {e}"); return None
        
    def display_water_balance_summary(df_summary_data):
        """Displays the new water balance summary page with filters, metrics, table, and chart."""
        st.title("ğŸ’§ Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ Ø­Ø³Ø§Ø¨Ø¯Ø§Ø±ÛŒ Ø¢Ø¨ - Ø®Ù„Ø§ØµÙ‡ Ø¨ÛŒÙ„Ø§Ù† Ø¢Ø¨")
        st.markdown("Ø®Ù„Ø§ØµÙ‡ Ø¨Ø±Ø¯Ø§Ø´Øª Ø¢Ø¨ (Ù…ÛŒÙ„ÛŒÙˆÙ† Ù…ØªØ± Ù…Ú©Ø¹Ø¨ - MCM) Ø¨Ø± Ø§Ø³Ø§Ø³ ÙÛŒÙ„ØªØ±Ù‡Ø§ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ÛŒ.")
        st.info("Ù†Ú©ØªÙ‡: Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¬Ø±ÛŒØ§Ù† Ø¨Ø±Ú¯Ø´ØªÛŒØŒ Ø¶Ø±Ø§ÛŒØ¨ Ø¨Ø±Ú¯Ø´Øª Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³ØªÙ†Ø¯. Ø³ØªÙˆÙ† ØªØ¬Ø¯ÛŒØ¯Ù¾Ø°ÛŒØ±ÛŒ Placeholder Ø§Ø³Øª.")

        # --- Filters ---
        col_f1, col_f2, col_f3, col_f4 = st.columns(4)
        with col_f1: # County
            county_options = ["Ù‡Ù…Ù‡"]
            if not df_summary_data.empty and 'County' in df_summary_data.columns: county_options.extend(sorted(list(set(c for c in df_summary_data['County'].dropna().unique() if c != 'Ù†Ø§Ù…Ø´Ø®Øµ'))))
            disabled_county = selected_county_sidebar != "Ù‡Ù…Ù‡"
            selected_county_summary = st.selectbox("Ø´Ù‡Ø±Ø³ØªØ§Ù†", options=county_options, key="county_summary_filter", index=county_options.index(selected_county_sidebar) if disabled_county else 0, disabled=disabled_county)
            if disabled_county: st.caption(f"ÙÛŒÙ„ØªØ± Ø´Ù‡Ø±Ø³ØªØ§Ù† '{selected_county_sidebar}' Ø§Ø¹Ù…Ø§Ù„ Ø´Ø¯Ù‡ Ø§Ø³Øª.")
        with col_f2: # Study Area
            study_areas = ["Ù‡Ù…Ù‡"]
            df_gw_summary = df_summary_data[df_summary_data['Source_Type'] == 'Groundwater']
            current_county = selected_county_summary if not disabled_county else selected_county_sidebar
            if current_county != "Ù‡Ù…Ù‡": df_gw_summary = df_gw_summary[df_gw_summary['County'] == current_county]
            if not df_gw_summary.empty and 'Study_Area' in df_gw_summary.columns: study_areas.extend(sorted(df_gw_summary['Study_Area'].dropna().unique()))
            selected_study_area = st.selectbox("Ù…Ø­Ø¯ÙˆØ¯Ù‡ Ù…Ø·Ø§Ù„Ø¹Ø§ØªÛŒ", options=list(set(study_areas)), key="study_area_filter")
        with col_f3: # Usage Type
            usage_types = ["Ù‡Ù…Ù‡"]
            if not df_summary_data.empty and 'Usage_Type' in df_summary_data.columns: usage_types.extend(sorted(list(set(u for u in df_summary_data['Usage_Type'].dropna().unique() if u != 'Ù†Ø§Ù…Ø´Ø®Øµ'))))
            selected_usage_type = st.selectbox("Ù†ÙˆØ¹ Ú©Ø§Ø±Ø¨Ø±ÛŒ", options=usage_types, key="usage_type_filter")
        with col_f4: # Source Classification
            source_options_dict = {"Ù‡Ù…Ù‡": "All", "Ø¢Ø¨ Ø³Ø·Ø­ÛŒ (Ø³Ø¯)": "Surface", "Ø¢Ø¨ Ø²ÛŒØ±Ø²Ù…ÛŒÙ†ÛŒ": "Groundwater", "Ø¢Ø¨ Ø§Ù†ØªÙ‚Ø§Ù„ÛŒ": "Transfer", "ØªØµÙÛŒÙ‡ Ø®Ø§Ù†Ù‡": "Wastewater"}
            available_sources = df_summary_data['Source_Type'].unique() if not df_summary_data.empty else []
            display_source_options = ["Ù‡Ù…Ù‡"] + [k for k, v in source_options_dict.items() if v in available_sources and v != "All"]
            selected_source_type_display = st.selectbox("Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ù…Ù†Ø¨Ø¹", options=display_source_options, key="source_type_filter")
            selected_source_type_val = source_options_dict.get(selected_source_type_display, "All")

        # Renewable Filter
        renewable_options = ["Ù‡Ù…Ù‡", "ØªØ¬Ø¯ÛŒØ¯Ù¾Ø°ÛŒØ±", "ØªØ¬Ø¯ÛŒØ¯Ù†Ø§Ù¾Ø°ÛŒØ±", "Ù†Ø§Ù…Ø´Ø®Øµ"]
        selected_renewable_status = st.selectbox("ØªØ¬Ø¯ÛŒØ¯Ù¾Ø°ÛŒØ±ÛŒ", options=renewable_options, key="renewable_filter")

        # --- Filter data ---
        df_summary_filtered = df_summary_data.copy()
        if not disabled_county and selected_county_summary != "Ù‡Ù…Ù‡": df_summary_filtered = df_summary_filtered[df_summary_filtered['County'] == selected_county_summary]
        if selected_study_area != "Ù‡Ù…Ù‡" and 'Study_Area' in df_summary_filtered.columns: df_summary_filtered = df_summary_filtered[~((df_summary_filtered['Source_Type'] == 'Groundwater') & (df_summary_filtered['Study_Area'] != selected_study_area))]
        if selected_usage_type != "Ù‡Ù…Ù‡": df_summary_filtered = df_summary_filtered[df_summary_filtered['Usage_Type'] == selected_usage_type]
        if selected_source_type_val != "All": df_summary_filtered = df_summary_filtered[df_summary_filtered['Source_Type'] == selected_source_type_val]
        if selected_renewable_status != "Ù‡Ù…Ù‡":
            if 'Renewable_Status' in df_summary_filtered.columns:
                status_to_check = ['Ù†Ø§Ù…Ø´Ø®Øµ', 'Unknown', None] if selected_renewable_status == "Ù†Ø§Ù…Ø´Ø®Øµ" else [selected_renewable_status]
                df_summary_filtered = df_summary_filtered[df_summary_filtered['Renewable_Status'].isin(status_to_check)]
            else: st.warning("Ø³ØªÙˆÙ† 'Renewable_Status' Ø¨Ø±Ø§ÛŒ Ø§Ø¹Ù…Ø§Ù„ ÙÛŒÙ„ØªØ± ØªØ¬Ø¯ÛŒØ¯Ù¾Ø°ÛŒØ±ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯.")

        # --- Display Metrics (in MCM) ---
        st.subheader("Ø®Ù„Ø§ØµÙ‡ Ù…Ù‚Ø§Ø¯ÛŒØ± Ø¨Ø±Ø¯Ø§Ø´Øª (Ù…ÛŒÙ„ÛŒÙˆÙ† Ù…ØªØ± Ù…Ú©Ø¹Ø¨ - MCM)")
        metric_col1, metric_col2, metric_col3, metric_col4 = st.columns(4)
        total_surface = df_summary_filtered[df_summary_filtered['Source_Type'] == 'Surface']['Extraction_MCM'].sum()
        metric_col1.metric("Ø¨Ø±Ø¯Ø§Ø´Øª Ø¢Ø¨ Ø³Ø·Ø­ÛŒ (Ø³Ø¯Ù‡Ø§)", f"{total_surface:,.2f}")
        total_gw = df_summary_filtered[df_summary_filtered['Source_Type'] == 'Groundwater']['Extraction_MCM'].sum()
        metric_col2.metric("Ø¨Ø±Ø¯Ø§Ø´Øª Ø¢Ø¨ Ø²ÛŒØ±Ø²Ù…ÛŒÙ†ÛŒ", f"{total_gw:,.2f}")
        total_transfer = df_summary_filtered[df_summary_filtered['Source_Type'] == 'Transfer']['Extraction_MCM'].sum()
        transfer_available = not df_all_data[df_all_data['Source_Type'] == 'Transfer'].empty # Check if data ever existed
        metric_col3.metric("Ø¨Ø±Ø¯Ø§Ø´Øª Ø¢Ø¨ Ø§Ù†ØªÙ‚Ø§Ù„ÛŒ", f"{total_transfer:,.2f}" if transfer_available else "N/A")
        total_wastewater = df_summary_filtered[df_summary_filtered['Source_Type'] == 'Wastewater']['Extraction_MCM'].sum()
        wastewater_available = not df_all_data[df_all_data['Source_Type'] == 'Wastewater'].empty # Check if data ever existed
        metric_col4.metric("ØªØµÙÛŒÙ‡ Ø®Ø§Ù†Ù‡", f"{total_wastewater:,.2f}" if wastewater_available else "N/A")

        # --- Prepare and Display Aggregated Table (in MCM) --- FIX: Aggregate before display
        st.subheader("Ø¬Ø¯ÙˆÙ„ Ø®Ù„Ø§ØµÙ‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙÛŒÙ„ØªØ± Ø´Ø¯Ù‡") # Changed title to reflect aggregation
        if not df_summary_filtered.empty:
            # Define columns to group by - ensure they exist
            group_by_cols = ['Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ù…Ù†Ø¨Ø¹', 'Ù†Ø§Ù… Ù…Ù†Ø¨Ø¹', 'Ø´Ù†Ø§Ø³Ù‡ Ø²ÛŒØ±Ø­ÙˆØ¶Ù‡', 'Ø´Ù‡Ø±Ø³ØªØ§Ù†', 'Ú©Ø§Ø±Ø¨Ø±ÛŒ', 'ÙˆØ¶Ø¹ÛŒØª ØªØ¬Ø¯ÛŒØ¯Ù¾Ø°ÛŒØ±ÛŒ']
            # Rename columns *before* grouping
            df_renamed_for_grouping = df_summary_filtered.rename(columns={
                'Extraction_MCM': 'Ø¨Ø±Ø¯Ø§Ø´Øª (MCM)',
                'ID': 'Ø´Ù†Ø§Ø³Ù‡ Ø²ÛŒØ±Ø­ÙˆØ¶Ù‡',
                'Usage_Type': 'Ú©Ø§Ø±Ø¨Ø±ÛŒ', 'County': 'Ø´Ù‡Ø±Ø³ØªØ§Ù†',
                'Source_Type': 'Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ù…Ù†Ø¨Ø¹', 'Source_Name': 'Ù†Ø§Ù… Ù…Ù†Ø¨Ø¹',
                'Renewable_Status': 'ÙˆØ¶Ø¹ÛŒØª ØªØ¬Ø¯ÛŒØ¯Ù¾Ø°ÛŒØ±ÛŒ'
            })
            # Ensure all group columns exist
            actual_group_cols = [col for col in group_by_cols if col in df_renamed_for_grouping.columns]

            if 'Ø¨Ø±Ø¯Ø§Ø´Øª (MCM)' in df_renamed_for_grouping.columns and actual_group_cols:
                # Aggregate the data
                aggregated_table = df_renamed_for_grouping.groupby(actual_group_cols, observed=False)['Ø¨Ø±Ø¯Ø§Ø´Øª (MCM)'].sum().reset_index()

                # Display the aggregated table
                st.dataframe(aggregated_table[actual_group_cols + ['Ø¨Ø±Ø¯Ø§Ø´Øª (MCM)']].style.format({'Ø¨Ø±Ø¯Ø§Ø´Øª (MCM)': '{:,.2f}'}))

                # --- Chart Generation (based on aggregated data) ---
                st.divider()
                st.subheader("Ù†Ù…ÙˆØ¯Ø§Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø®Ù„Ø§ØµÙ‡ Ø´Ø¯Ù‡")
                if not aggregated_table.empty:
                    chart_type = st.radio("Ø§Ù†ØªØ®Ø§Ø¨ Ù†ÙˆØ¹ Ù†Ù…ÙˆØ¯Ø§Ø±:", ('Ù…ÛŒÙ„Ù‡â€ŒØ§ÛŒ', 'Ø®Ø·ÛŒ', 'Ø¯Ø§ÛŒØ±Ù‡â€ŒØ§ÛŒ'), key="chart_select", horizontal=True)
                    try:
                        plot_data = aggregated_table.copy()
                        plot_data['Ø¨Ø±Ø¯Ø§Ø´Øª (MCM)'] = pd.to_numeric(plot_data['Ø¨Ø±Ø¯Ø§Ø´Øª (MCM)'], errors='coerce').fillna(0)
                        if chart_type == 'Ù…ÛŒÙ„Ù‡â€ŒØ§ÛŒ':
                            fig_chart = px.bar(plot_data, x='Ø´Ù‡Ø±Ø³ØªØ§Ù†', y='Ø¨Ø±Ø¯Ø§Ø´Øª (MCM)', color='Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ù…Ù†Ø¨Ø¹', title="Ø¨Ø±Ø¯Ø§Ø´Øª ØªØ¬Ù…ÛŒØ¹ÛŒ (MCM) Ø¨Ø± Ø§Ø³Ø§Ø³ Ø´Ù‡Ø±Ø³ØªØ§Ù† Ùˆ Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ù…Ù†Ø¨Ø¹", labels={'Ø´Ù‡Ø±Ø³ØªØ§Ù†': 'Ø´Ù‡Ø±Ø³ØªØ§Ù†', 'Ø¨Ø±Ø¯Ø§Ø´Øª (MCM)': 'Ù…Ø¬Ù…ÙˆØ¹ Ø¨Ø±Ø¯Ø§Ø´Øª (Ù…ÛŒÙ„ÛŒÙˆÙ† Ù…ØªØ± Ù…Ú©Ø¹Ø¨)', 'Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ù…Ù†Ø¨Ø¹': 'Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ù…Ù†Ø¨Ø¹'}, barmode='group')
                            fig_chart.update_layout(xaxis={'categoryorder':'total descending'})
                            st.plotly_chart(fig_chart, use_container_width=True)
                        elif chart_type == 'Ø®Ø·ÛŒ':
                            if len(selected_water_years) > 1:
                                line_plot_data = df_summary_filtered.groupby(['Water_Year_Str', 'Source_Type'])['Extraction_MCM'].sum().reset_index()
                                fig_chart = px.line(line_plot_data, x='Water_Year_Str', y='Extraction_MCM', color='Source_Type', title="Ø±ÙˆÙ†Ø¯ Ø¨Ø±Ø¯Ø§Ø´Øª (MCM) Ø¯Ø± Ø·ÙˆÙ„ Ø²Ù…Ø§Ù† Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†ÙˆØ¹ Ù…Ù†Ø¨Ø¹", labels={'Water_Year_Str': 'Ø³Ø§Ù„ Ø¢Ø¨ÛŒ', 'Extraction_MCM': 'Ù…Ø¬Ù…ÙˆØ¹ Ø¨Ø±Ø¯Ø§Ø´Øª (Ù…ÛŒÙ„ÛŒÙˆÙ† Ù…ØªØ± Ù…Ú©Ø¹Ø¨)', 'Source_Type': 'Ù†ÙˆØ¹ Ù…Ù†Ø¨Ø¹'}, markers=True).update_xaxes(categoryorder='array', categoryarray=sorted(line_plot_data['Water_Year_Str'].unique()))
                                st.plotly_chart(fig_chart, use_container_width=True)
                            else: st.warning("Ù†Ù…ÙˆØ¯Ø§Ø± Ø®Ø·ÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ø±ÙˆÙ†Ø¯ØŒ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø§Ù†ØªØ®Ø§Ø¨ Ø­Ø¯Ø§Ù‚Ù„ Ø¯Ùˆ Ø³Ø§Ù„ Ø¢Ø¨ÛŒ Ø¯Ø± ÙÛŒÙ„ØªØ± Ø¹Ù…ÙˆÙ…ÛŒ Ø¯Ø§Ø±Ø¯.")
                        elif chart_type == 'Ø¯Ø§ÛŒØ±Ù‡â€ŒØ§ÛŒ':
                            pie_col = st.selectbox("Ù†Ù…Ø§ÛŒØ´ ØªÙˆØ²ÛŒØ¹ Ø¨Ø± Ø§Ø³Ø§Ø³:", ('Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ù…Ù†Ø¨Ø¹', 'Ú©Ø§Ø±Ø¨Ø±ÛŒ', 'Ø´Ù‡Ø±Ø³ØªØ§Ù†'), key="pie_col_select")
                            if pie_col in plot_data.columns:
                                pie_data = plot_data.groupby(pie_col)['Ø¨Ø±Ø¯Ø§Ø´Øª (MCM)'].sum().reset_index()
                                # Filter out zero values for better pie chart visibility
                                pie_data = pie_data[pie_data['Ø¨Ø±Ø¯Ø§Ø´Øª (MCM)'] > 0]
                                if not pie_data.empty:
                                    fig_chart = px.pie(pie_data, names=pie_col, values='Ø¨Ø±Ø¯Ø§Ø´Øª (MCM)', title=f"ØªÙˆØ²ÛŒØ¹ Ø¯Ø±ØµØ¯ Ø¨Ø±Ø¯Ø§Ø´Øª (MCM) Ø¨Ø± Ø§Ø³Ø§Ø³ {pie_col}", hole=0.3)
                                    fig_chart.update_traces(textposition='inside', textinfo='percent+label')
                                    st.plotly_chart(fig_chart, use_container_width=True)
                                else:
                                    st.warning(f"Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø§ Ù…Ù‚Ø¯Ø§Ø± Ø¨Ø±Ø¯Ø§Ø´Øª Ù…Ø«Ø¨Øª Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ù†Ù…ÙˆØ¯Ø§Ø± Ø¯Ø§ÛŒØ±Ù‡â€ŒØ§ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ '{pie_col}' ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯.")
                            else: st.warning(f"Ø³ØªÙˆÙ† '{pie_col}' Ø¨Ø±Ø§ÛŒ Ø±Ø³Ù… Ù†Ù…ÙˆØ¯Ø§Ø± Ø¯Ø§ÛŒØ±Ù‡â€ŒØ§ÛŒ Ø¯Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ¬Ù…ÛŒØ¹ Ø´Ø¯Ù‡ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
                    except Exception as e: st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø±Ø³Ù… Ù†Ù…ÙˆØ¯Ø§Ø±: {e}")
                else: st.warning("Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¯Ø± Ø¬Ø¯ÙˆÙ„ Ø®Ù„Ø§ØµÙ‡ Ø¨Ø±Ø§ÛŒ Ø±Ø³Ù… Ù†Ù…ÙˆØ¯Ø§Ø± ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯.")

                # --- Shapefile Upload and Map Display ---
                st.divider()
                st.subheader("Ù†Ù‚Ø´Ù‡ Ù…Ø­Ø¯ÙˆØ¯Ù‡ Ùˆ Ø¨Ø±Ø¯Ø§Ø´Øª")
                uploaded_shp_zip = st.file_uploader("Ø¢Ù¾Ù„ÙˆØ¯ Ø´ÛŒÙ¾â€ŒÙØ§ÛŒÙ„ Ù…Ø­Ø¯ÙˆØ¯Ù‡ (ÙØ§ÛŒÙ„ .zip)", type="zip", key="shp_uploader")
                if uploaded_shp_zip is not None:
                    gdf = load_shapefile(uploaded_shp_zip)
                    if gdf is not None:
                        st.success("Ø´ÛŒÙ¾â€ŒÙØ§ÛŒÙ„ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ùˆ Ø®ÙˆØ§Ù†Ø¯Ù‡ Ø´Ø¯.")
                        shp_cols = gdf.columns.tolist()
                        likely_id_cols = [col for col in shp_cols if col.upper() in ('ID', 'SUBBASINID', 'SUBBASIN_I', 'IDENTIFIER', 'CODE')]
                        default_index = shp_cols.index(likely_id_cols[0]) if likely_id_cols else 0
                        id_col_shp = st.selectbox("Ø§Ù†ØªØ®Ø§Ø¨ Ø³ØªÙˆÙ† Ø´Ù†Ø§Ø³Ù‡ (ID) Ø¯Ø± Ø´ÛŒÙ¾â€ŒÙØ§ÛŒÙ„ Ø¨Ø±Ø§ÛŒ Ø§ØªØµØ§Ù„:", options=shp_cols, index=default_index)

                        if id_col_shp and not aggregated_table.empty:
                            try:
                                map_data = aggregated_table[['Ø´Ù†Ø§Ø³Ù‡ Ø²ÛŒØ±Ø­ÙˆØ¶Ù‡', 'Ø¨Ø±Ø¯Ø§Ø´Øª (MCM)']].copy()
                                map_data['Ø´Ù†Ø§Ø³Ù‡ Ø²ÛŒØ±Ø­ÙˆØ¶Ù‡'] = map_data['Ø´Ù†Ø§Ø³Ù‡ Ø²ÛŒØ±Ø­ÙˆØ¶Ù‡'].astype(str)
                                map_data_agg = map_data.groupby('Ø´Ù†Ø§Ø³Ù‡ Ø²ÛŒØ±Ø­ÙˆØ¶Ù‡')['Ø¨Ø±Ø¯Ø§Ø´Øª (MCM)'].sum().reset_index()
                                gdf_map = gdf[[id_col_shp, 'geometry']].copy()
                                gdf_map[id_col_shp] = gdf_map[id_col_shp].astype(str)
                                merged_gdf = gdf_map.merge(map_data_agg, left_on=id_col_shp, right_on='Ø´Ù†Ø§Ø³Ù‡ Ø²ÛŒØ±Ø­ÙˆØ¶Ù‡', how='left')
                                merged_gdf['Ø¨Ø±Ø¯Ø§Ø´Øª (MCM)'] = merged_gdf['Ø¨Ø±Ø¯Ø§Ø´Øª (MCM)'].fillna(0)

                                # Classification
                                color_col = 'Ø¨Ø±Ø¯Ø§Ø´Øª (MCM)'
                                color_map = "Viridis"
                                try:
                                    non_zero_values = merged_gdf['Ø¨Ø±Ø¯Ø§Ø´Øª (MCM)'][merged_gdf['Ø¨Ø±Ø¯Ø§Ø´Øª (MCM)'] > 0]
                                    if non_zero_values.nunique() >= 4:
                                        merged_gdf['Ú©Ù„Ø§Ø³_Ø¨Ø±Ø¯Ø§Ø´Øª'] = pd.qcut(non_zero_values, q=4, labels=False, duplicates='drop')
                                        merged_gdf['Ú©Ù„Ø§Ø³_Ø¨Ø±Ø¯Ø§Ø´Øª'] = 'Ú©Ù„Ø§Ø³ ' + (merged_gdf['Ú©Ù„Ø§Ø³_Ø¨Ø±Ø¯Ø§Ø´Øª'] + 1).astype(str)
                                        merged_gdf['Ú©Ù„Ø§Ø³_Ø¨Ø±Ø¯Ø§Ø´Øª'].fillna('Ø¨Ø¯ÙˆÙ† Ø¨Ø±Ø¯Ø§Ø´Øª', inplace=True)
                                        color_col = 'Ú©Ù„Ø§Ø³_Ø¨Ø±Ø¯Ø§Ø´Øª'
                                    else: st.info("ØªØ¹Ø¯Ø§Ø¯ Ù…Ù‚Ø§Ø¯ÛŒØ± Ù…Ù†Ø­ØµØ± Ø¨Ù‡ ÙØ±Ø¯ Ø¨Ø±Ø§ÛŒ Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ú©ÙˆØ§Ù†ØªØ§ÛŒÙ„ Ú©Ø§ÙÛŒ Ù†ÛŒØ³Øª. Ø§Ø² Ù…Ù‚Ø§Ø¯ÛŒØ± Ø®Ø§Ù… Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯.")
                                except Exception as e_class: st.warning(f"Ø®Ø·Ø§ Ø¯Ø± Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§: {e_class}. Ø§Ø² Ù…Ù‚Ø§Ø¯ÛŒØ± Ø®Ø§Ù… Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯.")

                                # Plot Map
                                st.write("Ù†Ù‚Ø´Ù‡ Ø±Ù†Ú¯â€ŒØ¨Ù†Ø¯ÛŒ Ø´Ø¯Ù‡ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¨Ø±Ø¯Ø§Ø´Øª (MCM):")
                                try: center_lat = merged_gdf.geometry.centroid.y.mean(); center_lon = merged_gdf.geometry.centroid.x.mean()
                                except: center_lat = 36.0; center_lon = 58.0
                                fig_map = px.choropleth_mapbox(merged_gdf, geojson=merged_gdf.geometry, locations=merged_gdf.index, color=color_col,
                                                            mapbox_style="carto-positron", zoom=7, center={"lat": center_lat, "lon": center_lon}, opacity=0.6,
                                                            hover_name=id_col_shp, hover_data={'Ø¨Ø±Ø¯Ø§Ø´Øª (MCM)': ':.2f'},
                                                            color_continuous_scale=color_map if color_col == 'Ø¨Ø±Ø¯Ø§Ø´Øª (MCM)' else None,
                                                            category_orders={'Ú©Ù„Ø§Ø³_Ø¨Ø±Ø¯Ø§Ø´Øª': sorted(merged_gdf['Ú©Ù„Ø§Ø³_Ø¨Ø±Ø¯Ø§Ø´Øª'].unique())} if color_col == 'Ú©Ù„Ø§Ø³_Ø¨Ø±Ø¯Ø§Ø´Øª' else None,
                                                            title="Ù†Ù‚Ø´Ù‡ Ø¨Ø±Ø¯Ø§Ø´Øª Ø¨Ø± Ø§Ø³Ø§Ø³ Ø²ÛŒØ±Ø­ÙˆØ¶Ù‡")
                                fig_map.update_layout(margin={"r":0,"t":30,"l":0,"b":0})
                                st.plotly_chart(fig_map, use_container_width=True)
                            except KeyError as e: st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§ØªØµØ§Ù„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ù‡ Ø´ÛŒÙ¾â€ŒÙØ§ÛŒÙ„: Ø³ØªÙˆÙ† Ø´Ù†Ø§Ø³Ù‡ '{e}' ÛŒØ§ÙØª Ù†Ø´Ø¯.")
                            except Exception as e: st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§ÛŒØ¬Ø§Ø¯ Ù†Ù‚Ø´Ù‡: {e}")
                        else: st.warning("Ù„Ø·ÙØ§Ù‹ Ø³ØªÙˆÙ† Ø´Ù†Ø§Ø³Ù‡ Ø¯Ø± Ø´ÛŒÙ¾â€ŒÙØ§ÛŒÙ„ Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯ Ùˆ Ù…Ø·Ù…Ø¦Ù† Ø´ÙˆÛŒØ¯ Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø§ØªØµØ§Ù„ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯.")


    # --- Main App Logic ---
    if app_mode == "ØªØ­Ù„ÛŒÙ„ Ø¬Ø²Ø¦ÛŒ":
        display_detailed_analysis(df_dam_detailed, df_gw_detailed)
    elif app_mode == "Ø®Ù„Ø§ØµÙ‡ Ø¨ÛŒÙ„Ø§Ù† Ø¢Ø¨":
        display_water_balance_summary(df_filtered)

    # --- Footer ---
    st.sidebar.divider()
    st.sidebar.info("Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯Ù‡ Ø¨Ø§ Streamlit.")
# --- Handle Authentication Status ---
elif authentication_status == False:
    st.error('Ù†Ø§Ù… Ú©Ø§Ø±Ø¨Ø±ÛŒ ÛŒØ§ Ø±Ù…Ø² Ø¹Ø¨ÙˆØ± Ø§Ø´ØªØ¨Ø§Ù‡ Ø§Ø³Øª')
elif authentication_status == None:
    st.warning('Ù„Ø·ÙØ§Ù‹ Ù†Ø§Ù… Ú©Ø§Ø±Ø¨Ø±ÛŒ Ùˆ Ø±Ù…Ø² Ø¹Ø¨ÙˆØ± Ø®ÙˆØ¯ Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯')
